\newcommand{\productions}{P}
\newcommand{\nonterminals}{N}
\newcommand{\terminals}{\Sigma}
\newcommand{\startsymbol}{S}
\newcommand{\grammar}{(\nonterminals, \terminals, \productions, \startsymbol)}
\chapter{Parsing}
\label{Parsing}
Parsing is about analysing the structure of a sequence of tokens coming from some alphabet. We only give a brief overview of it here.
We begin by introducing some concepts of parsing in Section \ref{Parsing-Defs}. Then, in Section \ref{Parsing-Algebra}, we tie these concept together with the algebra from Section \ref{Section:Algebra}, and finally, in Section \ref{Valiant's-spec}, we show that parsing is equivalent to computing the transitive closure of an upper triangular matrix.
In Section \ref{Valiant}, we then focus on a particular algorithm for computing the transitive closure, Valiant's algorithm, that we implement and prove correct using Agda.

\section{Definitions}
The goal of parsing is first to decide if a given sequence of tokens belongs to a given language, and second to describe its structure within the language.
For this, we consider process opposite to parsing: generating a string in a given language. To do this, one uses a grammar for the language, which contains rules that can be used to build strings belonging to the language.
%\subsection{Definitions}
\label{Parsing-Defs}
Here, we define concepts relevant to our thesis.
\begin{Definition}
  A \emph{grammar} $G$ is a tuple $\grammar$, where 
  \begin{itemize}
  \item $\nonterminals$ is a finite set of nonterminals.
  \item $\terminals$, is a finite set of terminals, with $\nonterminals \cap \terminals = \emptyset$.
  \item $\productions$, is a finite set of production rules, written as $\alpha \to \beta$, where $\alpha$ and $\beta$ are sequences of terminals and nonterminals, and $\alpha$ contains at least one nonterminal.
  \item $\startsymbol \in \nonterminals$ is the start symbol.
  \end{itemize}
  We use upper case letters to denote nonterminals, lower case letters to denote terminals and Greek letters to denote sequences of both terminals and nonterminals.
\end{Definition}
The terminals are the tokens that belong to the alphabet (and could be English words), while nonterminals are structural properties of sequence of tokens (for English words, they could stand for things like ``noun'' and ``verb phrase'').

A grammar generates a string of terminals by repeatedly applying production rules to the start symbol, until there are no nonterminals left.
The language generated by a grammar is the set of strings of terminals (or tokens) it generates.

Parsing is then the process of taking a string and figuring out what (if any) sequence of expansions might have produced it. Often, one creates a datastructure annotating the string with the nonterminals generating the parts of the string.

\begin{Example}
  \label{Arithmetic}
  We present a simple grammar for a language of arithmetic expressions (which appears in slightly modified form in \citep{Lange-Leiss}):
  \begin{itemize}
  \item $\terminals = \{1,\ldots , 9, +, *, (, )\}$,
  \item $\nonterminals = \{E, T, F, N\}$, for ``expression'', ``term'', ``factor'' and ``number'', respectively.
  \item The production rules are
    \begin{enumerate}
    \item \label{p1} $E \to T$
    \item \label{p2} $E \to E + T$
    \item \label{p3} $T \to F$
    \item \label{p4} $T \to T * F$ 
    \item \label{p5} $F \to ( E )$
    \item \label{p6} $F \to N$
    \item \label{p7} $N \to i$, for $i = 1$, \ldots $9$. 
    \end{enumerate}
  \item $S = E$.
  \end{itemize}
  In Figure \ref{Str-Gen}, we give an example of generating the string $3+5+7*(2+3) $ with this grammar. To parse the string, we begin at the bottom of the figure, and apply the rules ``backwards''.%In Figure \ref{Str-Par}, we parse the same string.
\end{Example}
\begin{figure}
    \centering
    \begin{tabular}{l||l}
      Symbols & Explanation \\\hline
      $E$ & Start symbol \\\hline
      $E + T$ & \ref{p2} on $E$ \\\hline
      $E + T + T$ & \ref{p2} on $E$ \\\hline
      $T + T + T$ & \ref{p1} on $E$ \\\hline
      $T + T + T * F$ & \ref{p4} on rightmost $T$ \\\hline
      $T + T + T * (E)$ & \ref{p5} on $F$ \\\hline
      $T + T + T * (T + T)$ & \ref{p2}, then \ref{p1} on $E$ \\\hline
      $N + N + N * (N + N)$ & \ref{p4}, then \ref{p6} on all $T$s \\\hline
      $3 + 5 + 7 * (2 + 3)$ & \ref{p7} on all $N$s \\\hline
    \end{tabular}
    \caption{Generating the string $3+5+7*(2+3)$ with the grammar in Example \ref{Arithmetic}.\label{Str-Gen}}
  \end{figure}
%\begin{figure}
%    \centering
%    \begin{tabular}{l||l}      
%      Symbols & Explanation \\\hline
%      $3 + 5 + 7 * (2 + 3)$ & Parse the numbers with \ref{p7} \\\hline
%      $N + N + N * (N + N)$ & \ref{p4}, then \ref{p6} on all $T$s \\\hline
%      $E$ & Start symbol \\\hline
%      $E + T$ & \ref{p2} on $E$ \\\hline
%      $E + T + T$ & \ref{p2} on $E$ \\\hline
%      $T + T + T$ & \ref{p1} on $E$ \\\hline
%      $T + T + T * F$ & \ref{p4} on rightmost $T$ \\\hline
%      $T + T + T * (E)$ & \ref{p5} on $F$ \\\hline
%      $T + T + T * (T + T)$ & \ref{p2}, then \ref{p1} on $E$ \\\hline
%    \end{tabular}
%    \caption{Generating the string $3+5+7*(2+3)$ with the grammar in Example \ref{Arithmetic}.\label{Str-Par}}
%  \end{figure}
We are not going to consider arbitrary grammars in this report, so we give two restrictions to the definition above: 
\begin{Definition}
  A grammar is \emph{context free} if the left hand side of every production rule is a single nonterminal: $A \to \beta$.
\end{Definition}
\begin{Definition}
  A grammar is in (reduced) Chomsky Normal Form (CNF) \citep{Chomsky} if the every production rule is of one of the following two forms:
  \begin{align*}
  A &\to a\\
  A &\to BC 
  \end{align*}
\end{Definition}
It is well known that any Context Free Grammar can be converted into a grammar in CNF (which generates the same language), with a size increase that is at most quadratic \citep{Lange-Leiss}.
In the remainder of the report, we only consider grammars in Chomsky Normal Form.
\begin{Example}
  \label{CNF-Ex}
  We give a grammar in Chomsky Normal Form generating the same language as the one in Example \ref{Arithmetic} (which again appears, slightly modified, in \citep{Lange-Leiss}) by introducing new nonterminals and production rules to get rid of the production rules which had the wrong form:
  \begin{itemize}
  \item $\terminals = \{1,\ldots , 9, +, *, (, )\}$ (the same as before),
  \item $\nonterminals = \{E, T, F, X, Y, Z, T_+, T_*, T_(, T_)\}$.
  \item The production rules (where $A \to \beta \mid \gamma$ is short for $A \to \beta$ and $A \to \gamma$, and $i = 1$, \ldots,  $9$) are:
    \begin{enumerate}
    \item$E  \to  TX \mid TY \mid T_( \mid i$
    \item$T  \to  TY \mid T_( \mid i$
    \item$F  \to  T_(Z \mid i$
    \item$X  \to  T_+T$
    \item$Y  \to  T_*F$
    \item$Z  \to  ET_)$
    \item$T_+ \to +$
    \item$T_* \to *$
    \item$T_( \to ($
    \item$T_) \to )$
    \end{enumerate}
%    \begin{tabular}{l r c l}
%    1.  &$E$  & $ \to$ & $TX \mid TY \mid T_( \mid i$\\
%    2.  &$T$  & $ \to$ & $TY \mid T_( \mid i$\\
%    3.  &$F$  & $ \to$ & $T_(Z \mid i$\\
%    4.  &$X$  & $ \to$ & $T_+T$ \\
%    5.  &$Y$  & $ \to$ & $T_*F$\\
%    6.  &$Z$  & $ \to$ & $ET_)$\\
%    7.  &$T_+$& $ \to$ & $+$\\
%    8.  &$T_*$& $ \to$ & $*$\\
%    9.  &$T_($& $ \to$ & $($\\
%    10.& $T_)$& $ \to$ & $)$\\
%    \end{tabular}
  \item $S = E$.
  \end{itemize}
\end{Example}
\section{Grammar as a nonassociative semiring}
\label{Parsing-Algebra}
The set of production rules for a grammar in Chomsky Normal Form which have the form $A \to BC$ could almost be used directly as a definition of multiplication on the nonterminals by replacing the arrows by equals signs:
\begin{equation*}
  BC = A
\end{equation*}
However, there are two problems with this. First, there can be nonterminals $B$ and $C$ with no production $A \to BC$. Second, there can be many different nonterminals that expand to the same thing: there can be $A_1$ and $A_2$ such that $A_1 \to BC$ and $A_2 \to BC$ are both productions.

The solution to these two problems is to instead consider \emph{sets} of nonterminals, with the following multiplication:
\begin{equation*}
  x \cdot y = \{A \st B \in x,\, C \in y,\, A \to BC \in P\}.
\end{equation*}

In general, this multiplication does not satisfy any algebraic axioms on its own, it is neither associative nor commutative.
Since we are considering sets, it is natural to choose set union as addition and hence $\emptyset$ as $0$, and with this, the above multiplication distributes over addition and the empty set is an absorbing (or zero) element for it.
That is, the sets with set union and the above multiplication form a nonassociative semiring (see Definition \ref{Def:NonassocSemiring}). In the remainder of the report, we will prove things for an arbitrary nonassociative semiring.
\section{A specification for parsing}
In this section, we find a specification for the problem of parsing a string with a grammar in Chomsky Normal Form. Then, in the next section, we compare it to the specification used in \citep{Valiant}.
%In this section, we reformulate the parsing problem for a grammar in CNF form as the problem of finding the transitive closure of an upper triangle matrix.
%Valiant showed this when defining his algorithm in \cite{Valiant}, but he uses a different specification of the transitive closure, which is  less suitable for proofs in Agda.

One approach to parsing a string $w$ of length $n$ is to form a matrix $X$ containing the sets of all non-terminals that generate a substring: if we define $w[i,j)$ to be the substring starting at the $i$th symbol in $w$ and ending at the $(j-1)$st, we let $X_{i j}$ be the set of all nonterminals generating of $w[i,j)$. The matrix formed this way is upper triangular since if $j \le i$, $X_{i j}$ is the set of all parses of an empty string.

Now, if we consider what nonterminals should be in the set $X_{i j}$, we note that:
\begin{itemize}
\item If $j = i + 1$, then $w[i,j)$ is a single token $a$. The only ways to generate $w[i,j)$ are using a production rules of the form $A \to a$, so $X_{i j}$ is the set of all $A$ such that $A \to a \in P$.
\item If $j > i + 1$, then $w[i,j)$ contains more than one token. The only ways to generate $w[i,j)$ are thus using a production rule $A \to BC$, where $B$ generates $w[i,k)$ and $C$ generates $w[k,j)$, for some $k$. For a fixed $k$, we find all nonterminals $A$ such that $A \to BC \in P$, where $B$ generates $w[i,k)$ and $C$ generates $w[k,j)$ by computing $X_{i k} \cdot X_{k j}$. Hence, 
            \begin{equation}
              X_{i j} = \bigcup_k X_{i k}\cdot X_{k j} = \sum_kX_{i k}X_{k j} = (XX)_{i j}
            \end{equation}
\end{itemize}
Combining the two points, we get:
\begin{equation}
  \label{TC}
  X = XX + C,
\end{equation}
where $C$ is the matrix whose only nonzero entries are $C_{i i+1} = \{A \st A \to w[i,i+1) \in P\}$. The above equation is the one we are going to use to derive Valiant's algorithm and prove it correct in Section \ref{Valiant}. 




%\section{Comparison with the specification used by Valiant}
\label{Valiant's-spec}
We now present the specification used in \citep{Valiant}, and prove that it is equivalent to our specification above \eqref{TC}. In particular, this implies that our specification defines a unique $X$, and proving that Valiant's algorithm computes it (in Section \ref{Valiant:Proof}) proves that it exists.

In \citep{Valiant}, the following definition of the transitive closure of a matrix is used:
\begin{Definition}
  The (non-associative) \emph{transitive closure} of an upper triangular square matrix $C$ is the matrix $C^+$ defined by
  \begin{equation}\label{VSpec}
    C^+ = \sum_{i = 1}^\infty \nap{C}{i},
  \end{equation}
  where $\nap{C}{n}$ is the sum of all possible products of $n$ factors $C$, defined recursively by:
  \begin{equation*}
    \nap{C}{1} = C \quad \text{and} \quad \nap{C}{n} = \sum_{i = 1}^{n - 1}\nap{C}{i}\nap{C}{n - i}.
  \end{equation*}
\end{Definition}
The sum in \eqref{VSpec} is actually finite, because as we mentioned in the end of Section \ref{Triangular-matrices}, any product of at least $n -1$ upper triangular matrices equals the zero matrix. Hence, if we show that $X$ defined in \eqref{TC} and $C^+$ defined in \eqref{VSpec} are equal, we can use \eqref{VSpec} to compute it, and it must be unique.
 \begin{Proposition}
   The two equations \eqref{TC} and \eqref{VSpec} are equivalent: If $C$ is upper triangular, then $X$ is upper triangular and satisfies
   \begin{equation}
     X = XX + C
   \end{equation}
   if and only if
   \begin{equation}
     X = \sum_{i = 1}^\infty \nap{C}{i}.
   \end{equation}
 \end{Proposition}
 \begin{proof}
   Assume first that $X = \sum_{i = 1}^\infty \nap{C}{i}= \sum_{i = 1}^{n-1}\nap{C}{i}$, where $n \times n$ is the size of $X$. It is clear that $X$ is upper triangular since $X$ is a sum of upper triangular matrices. Further, 
   \begin{equation*}
     X X = 
     \left(\sum_{i = 1}^{n-1}\nap{C}{i}\right)\left(\sum_{j = 1}^{n-1}\nap{C}{j}\right) =
     \sum_{i = 1}^{n - 1}\sum_{j = 1}^{n-1}\nap{C}{i}\nap{C}{j} = 
     \sum_{i = 1}^{n - 1}\sum_{j = 1}^{n - i - 1}\nap{C}{i}\nap{C}{j},
   \end{equation*}
   where the last equality holds because the remaining terms contain more than $n-1$ factors $C$, and hence equal zero.
   The above sum contains one copy of $\nap{C}{i}\nap{C}{j}$ for each $i = 1$, \ldots $n-1$ $j$ = $1$, $\ldots$, $n - i -1$. 
   Another way to sum these up (we can rearrange the sums since the addition is commutative) is to consider the sum $k = i + j$ and for each $k = 2$, \ldots, $n-1$ generate all products of $k$ factors. Hence, the above sum equals
   \begin{equation*}
     \sum_{k = 2}^{n-1}\sum_{l = 1}^{k-1}\nap{C}{l}\nap{C}{k-l} = \sum_{k = 2}^{n-1}\nap{C}{k},
   \end{equation*}
   and so, $XX + C = \sum_{k = 1}^{n-1}\nap{C}{k} = X$, and clearly.

   Next, we assume that $X$ is upper triangular and satisfies 
   \begin{equation*}
     \label{localdef}
     X = XX + C 
   \end{equation*}
   We define $R_k$ inductively by
   \begin{equation*}
     R_1 = XX + C \quad \text{ and } \quad R_{n + 1} = R_nR_n + C.
   \end{equation*}
   Since $X = R_1$, and if $X = R_n$, then by inserting $R_n$ in the right hand side of \eqref{localdef}, $X = R_nR_n + C = R_{n + 1}$, so by induction, $X = R_k$ for any $k$. We note also that after multiplying out (using the distributivity of multiplication over addition), $R_k$ is a sum of terms consisting of products of $X$ and $C$ (only). Now, we want to prove:
   \begin{enumerate}
   \item \label{1} For all $i$, $j \ge 1$, there is a $k$  such that $\nap{C}{i}\nap{C}{j}$ is a term in $R_k$.
   \item \label{2} If $\nap{C}{i}\nap{C}{j}$, for $i$, $j \ge 1$, is a term in $R_k$, then it is also a term in $R_{k + 1}$.
   \item \label{3} For every $k$, there are no structurally equal terms in $R_k$ (terms that are products of the same factors, in the same order, including parentheses).
   \item \label{4} The number of factors in terms containing $X$ in $R_k$ is at least $k + 1$. 
   \end{enumerate}
   From these facts, we can deduce that $X = \sum_{i = 1}^{n-1}\nap{C}{i}$: By \ref{1} and \ref{2}, there is a $R_k$ that contains all products $\nap{C}{i}\nap{C}{j}$ with $i < n - 1$, $j < n - 1$, and hence contains the sum $\sum_{i = 2}^{n-1}\nap{C}{i}$. By definition, it also contains $C$, so it contains $\sum_{i = 1}^{n-1}\nap{C}{i}$. Thus, (for example) $R_{k + n}$ also contains the whole sum. Since any term in $R_{k + n}$ involving $X$ contains at least $k + n + 1$ factors by \ref{4}, those terms are zero. So any other terms in $R_{k + n}$ are products of $C$s only. But any such term would either be a product of more than $n-1$  $C$s, and hence equal to zero, or a product of at most $n-1$ $C$s, and hence nonexistent since by \ref{3} there are no duplicates, and the term is in the sum $\sum_{i = 1}^{n-1}\nap{C}{i}$, so $X = R_{k + n} = \sum_{i = 1}^{n-1}\nap{C}{i}$.

We prove \ref{2} by induction on $i + j$. If $i+j = 2$, we get the statement that $CC$ is a term in every $R_k$, $k \ge 2$ (since it is a term in $R_2$) , but this is clearly true, since $R_{k - 1} = Y + C$, so that $R_{k} = (Y + C)(Y + C) + C = YY + YC + CY + CC + C$. If $i + j = n + 1$, and $\nap{C}{i}\nap{C}{j}$ is a term in $R_{k}$ for some $k \ge 2$, then from the definition of $R_k$, $\nap{C}{i}$ and $\nap{C}{j}$ are terms in $R_{k-1}$, and hence are terms in every $R_l$, $l \ge k-1$ by induction (since each of $\nap{C}{i}$ and $\nap{C}{j}$ are either equal to $C$ and hence a term in every $R_l$, or a sum of $\nap{C}{i'}{j'}$, with $i' + j' = i$ or $j$ which is at most $n$).

Next, we prove \ref{1}, again by induction on $i + j$. If $i + j = 2$, then $\nap{C}{i}\nap{C}{j} = CC$, which is a term in $R_2$. If $i + j = n + 1$, then there are $k_i$ and $k_j$ such that $\nap{C}{i}$ and $\nap{C}{j}$ are terms of $R_{k_i}$ and $R_{k_j}$ respectively (if $i$ or $j$ is $1$, then $R_1$ will do, otherwise we use induction, since $i$ and $j \le n$). Then if we let $k = \max(k_i,k_j)$, by \ref{2}, $R_k$ contains both, and hence, $R_{k+1}$ contains their product. 

We prove \ref{3} by induction on $k$. First, $R_1$ contains no structurally equal terms. Second, if $R_k$ contains no structurally equal terms, then if $R_{k+1}$ contains two structurally equal terms, they must both be products, say $X_1Y_1$ and $X_2Y_2$, and then, $R_{k}$ contains all four factors $X_1$, $Y_1$, $X_2$ and $Y_2$, but for $X_1Y_1$ to be structurally equal to $X_2Y_2$, their outermost parentheses must be equal, and so we must have that $X_1$ is structurally equal to $X_2$ and $Y_1$ is structurally equal to $Y_2$, since otherwise the placement of the parentheses would be different in the products. 

We prove \ref{4} by induction on $k$. In $R_1$, $XX$ is the only term containing $X$, and contains $2$ factors. If it is true for $k = n$, then when formin $R_{n+1}$, we multiply each term containing $X$, which contains at least $n + 1$ factors, by something and the result thus contains at least $n+2$ factors.
\end{proof}

Since we have proven that our specification \eqref{TC} is equivalent to Valiant's definition of transitive closure, \eqref{VSpec}, we will refer to our upper triangular matrix $X$ as the transitive closure of $C$. 

%%%% Comments
Although our specification \eqref{TC} is seemingly less ``computational'' than 
\eqref{VSpec}, which could be used to compute the transitive closure of $C$ by computing the value of the sum, ours is a lot simpler to use to derive Valiant's algorithm, as we do in Section \ref{Valiant:Der}. In particular, using our specification together with a block matrix makes Valiant's algorithm fall out almost immediately, while simply proving the correctness of it using \eqref{VSpec} is a difficult task.

Additionally, we feel that our specification ties in with the problem of parsing a string much more naturally than \eqref{VSpec} does. By considering elements of the parse chart, it is clear that the chart should satisfy \eqref{TC}, while to go from parsing to \eqref{VSpec} involves using the fact that an element of the parse chart should contain all possible ``formally distinct'' sequences of nonterminals \citep{Valiant}.

%We might also mention that our specification avoids mentioning anything about the non-associativity of multiplication.


%To end this section, we note that other possible specifications of the transitive closure, similar to \eqref{JPTSpec}, that are equivalent to it if we assume associativity (and that addition is idempotent) fail to be correct without associativity, one such is:
%\begin{equation}
%  C^+ = C^+C + C,
%\end{equation}
%and adding the extra term $CC^+$, to get
%\begin{equation}
%  C^+ = C^+C + CC^+ + C
%\end{equation}
%fails to make the specification correct, since when expanding them, these two only ever produce bracketings of the form $(\cdots(CC)\cdots) C$ (and $C(\cdots(CC)\cdots)$.

