\newcommand{\nanring}{nonassociative semiring}
\newcommand{\Nanring}{Nonassociative semiring}
\section{Algebra}
We are going to introduce a bunch of algebraic things that will be useful either later or as point of reference. They will also be useful as an example of using agda as a proof assistant!

The first two sections are about algebraic structures that are probably already known. Both for reference, and as examples. Then we go on to more general algebraic structures, more common in Computer Science, since they satisfy fewer axioms (more axioms mean more interesting structure---probably---but at the same time, it's harder to satisfy all the axioms.
\subsection{Introductory defintions}
Before covering some algebraic structures, we would like to define the things needed to talk about them in Agda. These are mainly propositions regarding functions and relations.
\subsubsection{Relation properties}
The first thing to discuss is the equivalence relation. It is a relation that acts like an equality.
\begin{Definition}
  A relation $R \subset X \times X$ is called an \emph{equivalence relation} if it is\todo{write sqiggly line instead of $R$}
  \begin{itemize}
  \item Reflexive: for $x \in X$, $x R x$.
  \item Symmetric: for $x$, $y \in X$, if $x R y$, then $y R x$.
  \item Transitive: for $x$, $y$, $z \in X$, if $x R y$ and $y R z$, then $x R z$.
  \end{itemize}
\end{Definition}
We formalize the way it behaves like an equality in the following proposition:
\begin{Proposition}
An equivalence relation $R$ partitions the elements of a set $X$ into disjoint nonempty equivalence classes (subsets $[x] = \{y \in X \st y R x\}$) satisfying: 
\begin{itemize}
\item For every $x \in X$, $x \in [x]$.
\item If $x \in [y]$, then $[x] = [y]$.
\end{itemize}
\end{Proposition}
If we replace the equality of elements with an equivalence relation, i.e., that two elements are ``equal'' if they belong to the same equivalence class, we get a coarser sense of equality. To see that it acts as the regular equality, we note that the equivalence relation is equality on equivalence classes.\todo{Expand/clean up on induced equality from equivalence classes.}

%include /Code/Algebra/Equivalence.lagda
\todo{ALL: is it possible to make underlines less ugly?}
\subsubsection{Operation Properties}\todo{THOMAS: Should we give these things names, or use them anyway? (i.e., |OP2| vs |A \to A \to A|}
Next, we define some properties that binary operation (i.e., functions $X \to X \to X$) can have. These are functions that are similar to ordinary addition and multiplication of numbers (if they have all the properties we define below---but it can be useful to think of them that way even if they don't).
\begin{Definition} %%% Associative
A binary operation $\cdot$ on a set $X$ is associative if $x \cdot (y \cdot z) = (x \cdot y) \cdot z$ for all $x$, $y$, $z \in X$.
\end{Definition}
In Agda code, the proposition that |_∙_| is associative, with respect to a given equivalence relation |_≈_| is given by the type:
%include Code/Algebra/Short/Associative.lagda

Most familiar basic mathematical operations, like addition and multiplication of numbers, are associative. On the other hand, operations like subtraction and division are not, since $x - (y - z) = x - y + z \ne (x - y) - z$, but this is because they are in some sense the combination of addition and inversion: $x - y = x + (-y)$. %One reason that many mathematical operations are associative is that they are in some sense transformations of something, and transformations are related 

In this thesis, we are very interested in a non-associative operation related to parsing.
\begin{Example}
Informally, we can define a multiplication on sequences of words, where ? \todo{THOMAS: write, maybe}
% Non-example of parsing
% Non-example of genetics ?
\end{Example}
\begin{Definition} %%% Commutative
A binary operation $\cdot$ on a set $X$ is commutative if $x \cdot y = y \cdot x$ for all $x$, $y \in X$.
\end{Definition}
In Agda, this proposition becomes the type
%include Code/Algebra/Short/Commutative.lagda
Again, many familiar basic mathematical operations are commutative, like addition and multiplication of numbers, are commutative, but matrix multiplication for matrices of size $n \times n$, $n \ge 2$ is an example of an operation that is not commutative.

\subsubsection{Properties of pairs of operations}
When we have two different binary operations on the same set, we often want them to interact with each other sensibly, where sensibly means as much as multiplication and addition of numbers interact as possible. 

%%%%%%%%%%%%%%%%%%
%% Distributivity
%%%%%%%%%%%%%%%%%%
We recall the distributive law $x\cdot(y + z) = x\cdot y + x\cdot z$, where $x$, $y$, and $z$ are numbers and $\cdot$ and $+$ are multiplication and addition and generalize it to arbitrary operations: 
\begin{Definition}
  A binary operation $\cdot$ on $X$ \emph{distributes over} a binary operation $+$ if, for all $x$, $y$, $z \in X$,
  \begin{itemize}
  \item $x \cdot (y + z) = x \cdot y + x \cdot z$,
  \item $(y + z) \cdot x = y \cdot x + z \cdot x$,
  \end{itemize}
  where we assume that $\cdot$ binds its arguments harder than $+$.
\end{Definition}
%include /Code/Algebra/Short/Distributive.lagda

%%%%%%%%%%%%%%%%%%
%% Zero
%%%%%%%%%%%%%%%%%%
\todo{THOMAS: Should zero be here, it only considers one operation}
The second such interaction axiom we will consider comes from the fact that $0$ absorbs when involved in a multiplication of numbers: $0 \cdot x = x \cdot 0 = 0$. In particular, if we have an operation $+$ to which we have an inverse and a neutral element $0$, we automatically get $0 \cdot x = 0$:
\begin{equation*}
  0 \cdot x = (0 + 0) \cdot x = 0 \cdot x + 0 \cdot x,
\end{equation*}
where the first equality follows from the fact that $0$ is a neutral element for $+$, and the second from that $\cdot$ distributes over $+$. We can then cancel $0 \cdot x$ on both sides to get $0 = 0 \cdot x$.% In Agda, we can formalize the above proof (and make sure we didn't use any other properties).

If we don't have inverses, we can't perform the final step (for example, if $+$ would happen to be idempotent: $x + x = x$ for all $x \in X$, like set union $\cup$, we could not conclude that $0 = 0 \cdot x$), and then, it makes sense to have the following as an axiom:
\begin{Definition}
  An element $0 \in X$ is a \emph{zero element} (also known as an \emph{absorbing element}) of a binary operation $\cdot$ if $0 \cdot x = x \cdot 0 = 0$ for every $x \in X$.
\end{Definition}
%include Code/Algebra/Short/Zero.lagda

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% GROUPS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Groups}
The first algebraic structure we will discuss is that of a group. We give first the mathematical definition, and then define it in Agda:
\begin{Definition}
A group is a set $G$ together with a binary operation $\cdot$ on $G$, satisfying the following:
\begin{itemize}
\item $\cdot$ is associative, that is, for all $x$, $y$, $z \in G$, $(x \cdot y) \cdot z = x \cdot (y \cdot z)$. 
\item There is an element $e \in G$ such that $e \cdot g = g \cdot e = g$ for every $g \in G$. This element is the \emph{neutral element} of $G$.
\item For every $g \in G$, there is an element $g^{-1}$ such that $g \cdot g^{-1} = g^{-1} \cdot g = e$. This element $g^{-1}$ is the \emph{inverse} of $g$.
\end{itemize}
\end{Definition}
\begin{Remark}
The set $G$ is sometimes called the \emph{carrier set} of the group. This is the name used in the Agda Standard Library for all algebraic structures.
\end{Remark}
\begin{Remark}
One usually refers to a group $(G, \cdot, e)$ simply by the name of the set $G$, in particular when the operation considered is fairly obvious.
\end{Remark}
\begin{Definition}
An group $(G, \cdot, e)$ is \emph{Abelian} if the binary operation $\cdot$ is commutative.
\end{Definition}
%\begin{Remark}
%$G$ doesn't actually need to be a set. \todo{should this be noted}
%\end{Remark}
An important reason to study groups that many common mathematical objects are groups. First there are groups where the set is a set of numbers:
\begin{Example}
  The integers $\Z$, the rational numbers $\Q$, the real numbers $\R$ and the complex numbers $\C$, all form groups when $\cdot$ is addition and $e$ is $0$.
\end{Example}
\begin{Example}
  The non-zero rational numbers $\Q\setminus{0}$, non-zero real numbers $\R\setminus{0}$, and non-zero complex numbers $\C\setminus{0}$, all form groups when $\cdot$ is multiplication and $e$ is $1$.
\end{Example}
Second, the symmetries of a 
% In Agda code, this is defined using a record:
%include /Code/Algebra/GroupDef.lagda


\subsubsection{Cayley Table / Examples / Finite groups}
We are mostly concerned with finite structures (although not groups) in this thesis, and these can be generated by a multiplication table (also known as a cayley table. We here give two examples of finite groups, to examplify the equational reasoning for algebraic structures.
% include z2xz2







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% MONOIDS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Monoids and related structures} % alternate title: genralizations
Here, we are going to discuss algebraic structures that are slightly more general than groups. These are important for programming, because it is rare that a datatype satisfies all the axioms of a group. First, we define monoids, which are a generalization of groups, and then we define magmas, which are an even further generalization.
\subsubsection{Definition}
Like a group, a monoid is a set with a binary operation, that satisfies some axioms. The difference is that now, we don't require that there is an inverse for each element.
\begin{Definition}
  A monoid is a set $M$, together with a binary operation $\cdot$ on $M$, that satisfies the following:
  \begin{itemize}
  \item $\cdot$ is associative, that is, for all $x$, $y$, $z \in M$, $(x \cdot y) \cdot z = x \cdot (y \cdot z)$. 
  \item There is an element $e \in M$ such that $e \cdot x = x \cdot e = x$ for every $x \in M$. This element is the \emph{neutral element} of $M$.
  \end{itemize}
\end{Definition}
%include Code/Algebra/Monoid.lagda

%\subsubsection{Cayley Table} remove this here, and instead refer back to definition of group.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% RING LIKE STRUCTURES (two operations on a set)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ring-like structures}
\subsubsection{Definitions}
As we discussed above, in Section \ref{two-operators}, when one has two operations on a set, one often wants them to interact sensibly. The basic example from algebra is a ring:
\begin{Definition}
A set $R$ together with two binary operations $+$ and $*$ (called addition and multiplication) forms a \emph{ring} if:
\begin{itemize}
\item It is an Abelian group with respect to $+$.
\item It is a monoid with respect to $*$.
\item $*$ distributes over $+$.
\end{itemize}
\end{Definition}
However, for the applications we have in mind, Parsing, the algebraic structure in question (see Section \ref{Parsing-as-algebraic structure}) does not even have associative multiplication (see section \ref{magma-monoid-like}), and does not have inverses for addition. We still have an additive $0$ (the empty set---representing no parse), and want it to be an absorbing element with regard to multiplication (if the left, say, substring has no parse, then the whole string has no parse). We also do not have a unit element for multiplication (there is no guarantee that there is a string $A$ such that $A$ followed by $X$ has the same parse as $X$ for every string $X$). But the proof that $0$ is an absorbing element depends crucially on the existence of the ability to cancel (implied by the existence of additive inverses in a group), as seen above. For this reason, we include as an axiom that zero absorbs.

There are a number of (fairly standard) \todo{THOMAS: Cite something} generalizations of the ring definition, but none matches our requirements. One generalization is the semiring, which has the same axioms, except that addition need not have inverses, and so we add the requirement that zero absorbs:
\begin{Definition}
A set $R$ together with two binary operations $+$ and $*$ forms a \emph{semiring} if:
\begin{itemize}
\item It is a commutative monoid with respect to $+$.
\item It is a monoid with respect to $*$.
\item $*$ distributes over $+$.
\item $0 * x = x * 0 = 0$ for all $x \in R$.
\end{itemize}
\end{Definition}
Another generalization is the nonassociative ring, which does away with the requirement that multiplication is associative and that there is an identity element for multiplication.
\begin{Definition}
A set $R$ together with two binary operations $+$ and $*$ forms a \emph{non-associative ring} if:
\begin{itemize}
\item It is an Abelian group with respect to $+$.
\item It is closed under $*$.
\item $*$ distributes over $+$.
\end{itemize}
\end{Definition}
We take this to mean that the modifier \emph{nonassociative} removes the requirement that the set together with $*$ is a monoid\todo{too horrible joke?} from the axioms of the structure. Hence, we make the following definition:
\begin{Definition}
A set $R$ together with two binary operations $+$ and $*$ forms a \emph{\nanring} if:
\begin{itemize}
\item It is a commutative monoid with respect to $+$.
\item $*$ distributes over $+$.
\item $0 * x = x * 0 = 0$ for all $x \in R$.
\end{itemize}
\end{Definition}
%include Code/Algebra/NANRing.lagda

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% MATRICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Matrices}
We recall that a matrix is in some sense really just a set of numbers formed in a rectangle, so there is nothing stopping us from defining one over an arbitrary ring, or even over a \nanring, as opposed to over $\R$ or $\C$. To be similar to the definition we will make in Agda of an abstract matrix (one without a specific implementation in mind), we consider a matrices of size $m \times n$ as a functions from a pair of natural numbers $(i,j)$, with $0 \le i < m$, $0 \le j < n$ (or more specifically, $i \in \Fin{m}$, $j \in \Fin{n}$, and hence, after currying define: 
\begin{Definition}
A \emph{matrix} $A$ over a set $R$ is a function $A : \Fin{m} \to \Fin{n} \to R$. 
\end{Definition}
When talking about matrices from a mathematical point of view, we will write $A_{i j}$ for $A\, i\, j$

%include Code/Algebra/Matrix.lagda

If $R$ is a ring or a \nanring, we can define addition and multiplication of matrices with the usual formulas:
\begin{align*}
  (A + B)_{i j} &= A_{i j} + B_{i j} 
  \intertext{and}
  (A B)_{i j} &= \sum_{k = 1}^n A_{i k} B_{k j} 
\end{align*}

%include /Code/Algebra/MatrixOperations.lagda

The most interesting fact about matrices (to our application) is the following two propositions:
\begin{Proposition}
If $R$ is a a ring (\nanring), then the matrices of size $n \times n$ over $R$ also form a ring (\nanring). Actually, matrices over $R$ of arbitrary size form an Abelian group (commutative monoid) under matrix addition. In both cases, the zero matrix plays the role of the neutral element.
\end{Proposition}
The proof is fairly easy but boring. We provide part of the proof when $R$, is particualar, we prove that addition is commutative, and that multiplication is ?\todo{THOMAS: WHAT}. is a \nanring in Agda (because it is the case we will make use of later).
%include /Code/Algebra/MatrixProof.lagda
\subsection{Triangular Matrices}
For our applications, we will be interested in matrices that have no non-zero elements on or below the diagonal.
\begin{Definition}
  A matrix is \emph{upper triangular} if all elements on or below its diagonal are equal to zero.
\end{Definition}
Since we are only interested in upper triangular matrices, we will sometimes refer to them as just \emph{triangular} matrices.% We generalize the defintion to matrices that have zeros on their super diagonals too.




%\begin{Definition}         TRIANGULARITY???
%  An upper triangular matrix has \emph{triangularity} $d$ if all elements on or below its $d$th super diagonal are zero. \todo{are they called super diagonals?}
%\end{Definition}
%That is, if $i \le j + d$ implies that $A_{i j} = 0$. An upper triangular matrix thus has triangularity $0$, an upper triangular matrix where the line above the diagonal also contains \todo{line is not a good word} zeros has triangularity $1$ and so on. See Figure \ref{Figure:TriangularityExample}
%\begin{figure}
%  \centering
%  \missingfigure{matrix with positive triangularity \label{Figure:TriangularityExample}}
%\end{figure}

%include /Code/Algebra/Triangle.lagda

%continues until it is proven in Triangle.lagda, since there isn't really anthing mathematical to say
